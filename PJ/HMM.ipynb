{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01abb4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from dsp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d338cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def readDat(filepath):\n",
    "#     # 使用16位有符号整数(int16)格式读取原始数据\n",
    "#     y = np.fromfile(filepath, dtype=np.int16)\n",
    "#     # 将整数值归一化到[-1, 1]范围\n",
    "#     y = y.astype(np.float32) / 32768.0\n",
    "#     return y\n",
    "def readDat(filepath):\n",
    "    ext = os.path.splitext(filepath)[1].lower()\n",
    "    if ext == '.dat':\n",
    "        y = np.fromfile(filepath, dtype=np.int16)\n",
    "        y = y.astype(np.float32) / 32768.0\n",
    "        return y\n",
    "    elif ext == '.wav':\n",
    "        y, _ = librosa.load(filepath, sr=8000)\n",
    "        return y\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的音频格式: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8200eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征提取\n",
    "def extractFeature(audio_file, sr=8000, win=256, step=160):\n",
    "    y = readDat(audio_file)\n",
    "    \n",
    "    segments = vad(y, sr, win, step)\n",
    "\n",
    "    if len(segments) == 0:\n",
    "        print(f\"警告: {audio_file} 没有检测到语音段\")\n",
    "        return None\n",
    "    \n",
    "    # 取所有音频段的起始和结束时间\n",
    "    start = segments[0][0]\n",
    "    end = segments[-1][1]\n",
    "    y_speech = y[int(start):int(end)]\n",
    "    \n",
    "    # 确保语音段足够长\n",
    "    min_length = win * 2  # 确保能生成至少一个完整的STFT帧\n",
    "    if len(y_speech) < min_length:\n",
    "        print(f\"警告: {audio_file} 语音段太短({len(y_speech)}采样点)，填充至{min_length}采样点\")\n",
    "        y_speech = np.pad(y_speech, (0, min_length - len(y_speech)), 'constant')\n",
    "        # return None\n",
    "\n",
    "    # 提取 MFCC 特征\n",
    "    mfcc_feature = computeMFCC(y_speech, sr, win, D=13, M=26)\n",
    "    \n",
    "    n_frames = mfcc_feature.shape[1]\n",
    "    if n_frames < 3:\n",
    "        print(f\"警告: {audio_file} 帧数太少({n_frames})，跳过该样本\")\n",
    "        return None\n",
    "\n",
    "    # 计算一阶差分（ΔMFCC）\n",
    "    delta = np.diff(mfcc_feature, n=1, axis=1)\n",
    "    delta = np.pad(delta, ((0,0),(1,0)), mode='edge')  # 保持帧数一致\n",
    "\n",
    "    # 计算二阶差分（ΔΔMFCC）\n",
    "    delta2 = np.diff(mfcc_feature, n=2, axis=1)\n",
    "    delta2 = np.pad(delta2, ((0,0),(2,0)), mode='edge')  # 保持帧数一致\n",
    "\n",
    "    # 拼接特征 [MFCC; ΔMFCC; ΔΔMFCC]\n",
    "    feature = np.vstack([mfcc_feature, delta, delta2])  # shape: (39, n_frames)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6286bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据集\n",
    "def prepareData(base_dir, classes):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    print(f\"开始从 {base_dir} 加载数据...\")\n",
    "    \n",
    "    total_files = 0         # 总文件数\n",
    "    error_files = 0         # 出错的文件数\n",
    "    \n",
    "    # 先计算总文件数\n",
    "    for idx, name in enumerate(classes):\n",
    "        class_dir = os.path.join(base_dir, str(idx).zfill(2))\n",
    "        if os.path.exists(class_dir):\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.endswith('.dat'):\n",
    "                    total_files += 1\n",
    "    print(f\"找到 {total_files} 个文件\")\n",
    "    \n",
    "    with tqdm(total=total_files, desc=\"总进度\") as pbar:\n",
    "        for idx, name in enumerate(classes):\n",
    "            class_dir = os.path.join(base_dir, str(idx).zfill(2))\n",
    "            \n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"警告：目录 {class_dir} 不存在，跳过类别 '{name}'\")\n",
    "                continue\n",
    "                \n",
    "            class_files = [f for f in os.listdir(class_dir) if f.endswith('.dat')]\n",
    "            print(f\"正在处理类别 '{name}' ({len(class_files)}个文件)...\")\n",
    "            \n",
    "            for filename in class_files:\n",
    "                filepath = os.path.join(class_dir, filename)\n",
    "                feature = extractFeature(filepath)\n",
    "                if feature is not None:\n",
    "                    features.append(feature)\n",
    "                    labels.append(idx)\n",
    "                else:\n",
    "                    error_files += 1\n",
    "\n",
    "                pbar.set_postfix({\"出错文件数\": error_files})\n",
    "                pbar.update(1)\n",
    "            \n",
    "    print(f\"\\n处理完成: 共 {total_files} 个文件, 出错 {error_files} 个\")\n",
    "    if len(features) == 0:\n",
    "        raise ValueError(\"没有成功处理任何文件!请检查数据路径和文件格式\")\n",
    "    \n",
    "    return features, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5066e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# HMM 语音识别器\n",
    "class HMMRecognizer:\n",
    "    # n_states: 隐藏状态数量\n",
    "    # n_mix: 每个状态的高斯混合数量\n",
    "    # cov_type: 协方差类型 ('diag'/'full')\n",
    "    # n_iter: 训练迭代次数\n",
    "    def __init__(self, n_state=5, n_mix=8, cov_type='diag', n_iter=20):\n",
    "        self.n_states = n_state\n",
    "        self.n_mix = n_mix\n",
    "        self.cov_type = cov_type\n",
    "        self.n_iter = n_iter\n",
    "        self.models = {}  # 存储每个类别的 HMM 模型\n",
    "        self.classes = None\n",
    "        \n",
    "    def train(self, features, labels):\n",
    "        self.classes = np.unique(labels)\n",
    "        \n",
    "        print(f\"开始训练HMM模型, 共{len(self.classes)}个类别...\")\n",
    "        \n",
    "        for c in tqdm(self.classes):\n",
    "            # 获取当前类别的所有特征\n",
    "            class_features = [feat for feat, label in zip(features, labels) if label == c]\n",
    "            \n",
    "            if len(class_features) == 0:\n",
    "                print(f\"警告: 类别{c}没有训练样本\")\n",
    "                continue\n",
    "            \n",
    "            # 将特征转换为适合HMM训练的格式\n",
    "            # 1. 首先计算所有样本的总帧数\n",
    "            total_frames = sum(feat.shape[1] for feat in class_features)\n",
    "            \n",
    "            # 2. 创建一个大的连续特征数组\n",
    "            X = np.zeros((total_frames, class_features[0].shape[0]))\n",
    "            \n",
    "            # 3. 填充特征并记录每个样本的长度\n",
    "            lengths = []\n",
    "            idx = 0\n",
    "            for feat in class_features:\n",
    "                seq_len = feat.shape[1]\n",
    "                X[idx:idx+seq_len] = feat.T  # 转置以匹配HMM输入要求\n",
    "                lengths.append(seq_len)\n",
    "                idx += seq_len\n",
    "            \n",
    "            # 初始化并训练HMM模型\n",
    "            model = hmm.GMMHMM(\n",
    "                n_components=self.n_states,\n",
    "                n_mix=self.n_mix,\n",
    "                covariance_type=self.cov_type,\n",
    "                n_iter=self.n_iter,\n",
    "                verbose=False,              # 是否打印训练过程信息\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                model.fit(X, lengths)  # 现在X的形状是(总帧数, 特征维度)\n",
    "                self.models[c] = model\n",
    "                print(f\"类别 {c} 模型训练完成\")\n",
    "            except Exception as e:\n",
    "                print(f\"类别 {c} 模型训练失败: {e}\")\n",
    "    \n",
    "    # 语音识别\n",
    "    # feature: MFCC特征，形状为(n_features, n_frames)\n",
    "    def recognize(self, feature):\n",
    "        if not self.models:\n",
    "            raise ValueError(\"模型尚未训练\")\n",
    "        \n",
    "        # 计算每个模型的对数似然\n",
    "        log_likelihoods = {}\n",
    "        for class_idx, model in self.models.items():\n",
    "            try:\n",
    "                # 计算当前特征在该模型下的对数似然\n",
    "                log_likelihood = model.score(feature.T)\n",
    "                log_likelihoods[class_idx] = log_likelihood\n",
    "            except Exception as e:\n",
    "                print(f\"计算类别 {class_idx} 的似然值时出错: {e}\")\n",
    "                log_likelihoods[class_idx] = -np.inf\n",
    "        \n",
    "        # 选择对数似然最高的类别\n",
    "        if not log_likelihoods:\n",
    "            return None, None\n",
    "        \n",
    "        best_class = max(log_likelihoods, key=log_likelihoods.get)\n",
    "        return best_class, log_likelihoods[best_class]\n",
    "    \n",
    "    # 保存模型到文件\n",
    "    def save(self, filepath):\n",
    "        joblib.dump({\n",
    "            'models': self.models,\n",
    "            'classes': self.classes,\n",
    "            'n_states': self.n_states,\n",
    "            'n_mix': self.n_mix,\n",
    "            'cov_type': self.cov_type\n",
    "        }, filepath)\n",
    "        \n",
    "    def load(self, filepath):\n",
    "        \"\"\"加载模型\"\"\"\n",
    "        data = joblib.load(filepath)\n",
    "        self.models = data['models']\n",
    "        self.classes = data['classes']\n",
    "        self.n_states = data['n_states']\n",
    "        self.n_mix = data['n_mix']\n",
    "        self.cov_type = data['cov_type']\n",
    "        \n",
    "    # 评估模型\n",
    "    def evaluate(self, features, true_labels):\n",
    "        predictions = []\n",
    "        \n",
    "        print(\"开始评估模型...\")\n",
    "        for i, feature in enumerate(tqdm(features)):\n",
    "            pred_class, _ = self.recognize(feature)\n",
    "            predictions.append(pred_class)\n",
    "            \n",
    "        # 计算准确率\n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "        print(f\"准确率: {accuracy:.4f}\")\n",
    "        \n",
    "        # 计算混淆矩阵\n",
    "        cm = confusion_matrix(true_labels, predictions)\n",
    "        \n",
    "        # 分类报告\n",
    "        report = classification_report(true_labels, predictions)\n",
    "        print(\"分类报告:\")\n",
    "        print(report)\n",
    "        \n",
    "        return accuracy, cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d678e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = HMMRecognizer(\n",
    "    n_state=5,  # 隐藏状态数\n",
    "    n_mix=4,    # 每个状态的高斯混合数\n",
    "    cov_type='diag', \n",
    "    n_iter=30   # 训练迭代次数\n",
    ")\n",
    "\n",
    "classes = [\"数字\", \"语音\", \"语言\", \"处理\", \"中国\", \"忠告\", \"北京\", \"背景\", \"上海\", \"商行\",\n",
    "              \"Speech\", \"Speaker\", \"Signal\", \"Sequence\", \"Processing\", \"Print\", \"Project\", \"File\", \"Open\", \"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4820c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据集\n",
    "# features, labels = prepareData('../myData', classes)\n",
    "features, labels = prepareData('../Data', classes)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "print(f\"训练集: {len(X_train)} 个样本\")\n",
    "print(f\"测试集: {len(X_test)} 个样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef37636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "recognizer.train(X_train, y_train)\n",
    "\n",
    "# 保存模型\n",
    "recognizer.save(\"hmm/hmm_models.pkl\")\n",
    "\n",
    "# 评估模型\n",
    "accuracy, cm, report = recognizer.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[str(i) for i in recognizer.classes],\n",
    "            yticklabels=[str(i) for i in recognizer.classes])\n",
    "plt.xlabel('Predict Type')\n",
    "plt.ylabel('True Type')\n",
    "plt.title('HMM Speech Recognition Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a48300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 识别单个语音文件\n",
    "# audio_file: 语音文件路径\n",
    "# recognizer: HMM识别器\n",
    "# class_names: 类别名称列表\n",
    "def recognize_speech_file(audio_file, recognizer, class_names):\n",
    "    # 提取特征\n",
    "    feature = extractFeature(audio_file)\n",
    "    if feature is None:\n",
    "        return \"无法检测到语音\", None\n",
    "    \n",
    "    # 使用HMM进行识别\n",
    "    class_idx, log_likelihood = recognizer.recognize(feature)\n",
    "    \n",
    "    if class_idx is None:\n",
    "        return \"识别失败\", None\n",
    "    \n",
    "    return class_names[class_idx], log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6aa5528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算类别 19 的似然值时出错: startprob_ must sum to 1 (got nan)\n",
      "录音 (2).wav -> 识别结果: 数字, 对数似然值: -7287.006115198465\n",
      "计算类别 19 的似然值时出错: startprob_ must sum to 1 (got nan)\n",
      "录音 (3).wav -> 识别结果: 语言, 对数似然值: -11470.018310817733\n",
      "计算类别 19 的似然值时出错: startprob_ must sum to 1 (got nan)\n",
      "录音 (4).wav -> 识别结果: 语音, 对数似然值: -9291.867593289287\n",
      "计算类别 19 的似然值时出错: startprob_ must sum to 1 (got nan)\n",
      "录音.wav -> 识别结果: File, 对数似然值: -10622.3388735593\n"
     ]
    }
   ],
   "source": [
    "# 测试识别\n",
    "recognizer.load(\"hmm/hmm_models.pkl\")               # 加载模型\n",
    "test_dir = \"/mnt/c/Users/Keats/Documents/录音/\"     # 测试目录\n",
    "# test_dir = \"../records/22300240008-曹奕伦-录音/22300240008-曹奕伦-录音\"\n",
    "\n",
    "# 保存原始stderr\n",
    "stderr_fileno = sys.stderr\n",
    "sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.endswith('.dat') or filename.endswith('.wav'):\n",
    "        test_file = os.path.join(test_dir, filename)\n",
    "        pred_class, log_likelihood = recognize_speech_file(test_file, recognizer, classes)\n",
    "        print(f\"{filename} -> 识别结果: {pred_class}, 对数似然值: {log_likelihood}\")\n",
    "\n",
    "# 恢复stderr\n",
    "sys.stderr.close()\n",
    "sys.stderr = stderr_fileno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cao, y_cao = prepareData('../records/22300240008-曹奕伦-录音/22300240008-曹奕伦-录音', classes)  # 重新准备测试数据集\n",
    "accuracy, cm, report = recognizer.evaluate(X_cao, y_cao)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
