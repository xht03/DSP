{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fedb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from dsp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc18ed",
   "metadata": {},
   "source": [
    "我们希望使用 SVM 实现语音识别，步骤如下：\n",
    "\n",
    "1. 特征提取\n",
    "\n",
    "2. 模型训练\n",
    "\n",
    "3. 模型识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6030fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDat(filepath):\n",
    "    # 使用16位有符号整数(int16)格式读取原始数据\n",
    "    y = np.fromfile(filepath, dtype=np.int16)\n",
    "    # 将整数值归一化到[-1, 1]范围\n",
    "    y = y.astype(np.float32) / 32768.0\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c641e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20310,)\n"
     ]
    }
   ],
   "source": [
    "y = readDat('22307110206-00-01.dat')\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b25837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征提取\n",
    "def extractFeature(audio_file, sr=8000, win=256):\n",
    "    y = readDat(audio_file)\n",
    "    \n",
    "    segments = vad(y, sr, win, win//2)\n",
    "\n",
    "    if len(segments) == 0:\n",
    "        print(\"No segments found.\")\n",
    "        return None\n",
    "    \n",
    "    # 取所有音频段的起始和结束时间\n",
    "    start = segments[0][0]\n",
    "    end = segments[-1][1]\n",
    "    y_speech = y[int(start):int(end)]\n",
    "\n",
    "    # 确保语音段足够长\n",
    "    min_length = win * 2  # 确保能生成至少一个完整的STFT帧\n",
    "    if len(y_speech) < min_length:\n",
    "        print(f\"警告: {audio_file} 语音段太短({len(y_speech)}采样点)，填充至{min_length}采样点\")\n",
    "        y_speech = np.pad(y_speech, (0, min_length - len(y_speech)), 'constant')\n",
    "\n",
    "    # print(\"Start time:\", start)\n",
    "    # print(\"End time:\", end)\n",
    "    # print(\"Segment Num:\", len(segments))\n",
    "    # print(\"-\" * 20)\n",
    "\n",
    "    # 提取MFCC特征\n",
    "    mfcc_feature = computeMFCC(y_speech, sr, win, D=13, M=26)\n",
    "\n",
    "    mfcc_mean = np.mean(mfcc_feature, axis=1)\n",
    "    mfcc_std = np.std(mfcc_feature, axis=1)\n",
    "\n",
    "    feature = np.concatenate([mfcc_mean, mfcc_std])\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "036cf553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据集\n",
    "# def prepareData(base_dir, classes):\n",
    "#     features = []\n",
    "#     labels = []\n",
    "    \n",
    "#     total_files = 0         # 总文件数\n",
    "#     processed_files = 0     # 处理的文件数\n",
    "    \n",
    "#     print(\"计算总文件数...\")\n",
    "#     for idx, name in enumerate(classes):\n",
    "#         class_dir = os.path.join(base_dir, str(idx).zfill(2))\n",
    "#         if os.path.exists(class_dir):\n",
    "#             for filename in os.listdir(class_dir):\n",
    "#                 if filename.endswith('.dat'):\n",
    "#                     total_files += 1\n",
    "#     print(f\"找到 {total_files} 个文件\")\n",
    "    \n",
    "#     for idx, name in enumerate(classes):\n",
    "#         class_dir = os.path.join(base_dir, str(idx).zfill(2))\n",
    "#         if not os.path.exists(class_dir):\n",
    "#             print(f\"警告: 目录 {class_dir} 不存在\")\n",
    "#             continue\n",
    "            \n",
    "#         print(f\"处理类别 {idx}: {name}\")\n",
    "#         for filename in os.listdir(class_dir):\n",
    "#             if filename.endswith('.dat'):\n",
    "#                 filepath = os.path.join(class_dir, filename)\n",
    "#                 feature = extractFeature(filepath)\n",
    "#                 if feature is not None:\n",
    "#                     features.append(feature)\n",
    "#                     labels.append(idx)\n",
    "                \n",
    "#                 processed_files += 1\n",
    "#                 percent = processed_files / total_files * 100\n",
    "#                 print(f\"\\r进度: [{processed_files}/{total_files}] {percent:.1f}%\", end=\"\")\n",
    "    \n",
    "#     print(\"\\n处理完成!\")\n",
    "#     return np.array(features), np.array(labels)\n",
    "\n",
    "# 准备数据集\n",
    "def prepareData(base_dir, classes):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    print(f\"开始从 {base_dir} 加载数据...\")\n",
    "    \n",
    "    total_files = 0         # 总文件数\n",
    "    processed_files = 0     # 处理了的文件数\n",
    "    error_files = 0         # 出错的文件数\n",
    "    \n",
    "    # 先计算总文件数\n",
    "    for idx, name in enumerate(classes):\n",
    "        class_dir = os.path.join(base_dir, str(idx).zfill(2))\n",
    "        if os.path.exists(class_dir):\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.endswith('.dat'):\n",
    "                    total_files += 1\n",
    "    print(f\"找到 {total_files} 个文件\")\n",
    "    \n",
    "    # 创建总进度条\n",
    "    with tqdm(total=total_files, desc=\"总进度\") as pbar:\n",
    "        for idx, name in enumerate(classes):\n",
    "            class_dir = os.path.join(base_dir, str(idx).zfill(2))\n",
    "            \n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"警告：目录 {class_dir} 不存在，跳过类别 '{name}'\")\n",
    "                continue\n",
    "                \n",
    "            class_files = [f for f in os.listdir(class_dir) if f.endswith('.dat')]\n",
    "            print(f\"正在处理类别 '{name}' ({len(class_files)}个文件)...\")\n",
    "            \n",
    "            for filename in class_files:\n",
    "                filepath = os.path.join(class_dir, filename)\n",
    "                try:\n",
    "                    feature = extractFeature(filepath)\n",
    "                    if feature is not None:\n",
    "                        features.append(feature)\n",
    "                        labels.append(idx)\n",
    "                    else:\n",
    "                        error_files += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"处理文件 {filepath} 出错: {str(e)}\")\n",
    "                    error_files += 1\n",
    "                \n",
    "                processed_files += 1\n",
    "                pbar.update(1)\n",
    "            \n",
    "    print(f\"\\n处理完成: 共 {total_files} 个文件, 成功 {processed_files - error_files} 个, 失败 {error_files} 个\")\n",
    "    if len(features) == 0:\n",
    "        raise ValueError(\"没有成功处理任何文件!请检查数据路径和文件格式\")\n",
    "    \n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0cda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# 训练SVM模型\n",
    "def train_svm_model(features, labels, test_size=0.2, random_state=42):\n",
    "    # 分割训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=test_size, random_state=random_state, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # 特征标准化\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 训练SVM模型\n",
    "    svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 评估模型\n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # 保存模型和标准化器\n",
    "    joblib.dump(svm, 'svm_model.pkl')\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    \n",
    "    return svm, scaler, (X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型进行识别\n",
    "def recognize_speech(audio_file, model, scaler, class_names):\n",
    "    # 提取特征\n",
    "    feature = extractFeature(audio_file)\n",
    "    if feature is None:\n",
    "        return \"无法检测到语音\"\n",
    "    \n",
    "    # 标准化特征\n",
    "    features_scaled = scaler.transform(feature.reshape(1, -1))\n",
    "    \n",
    "    # 预测\n",
    "    probabilities = model.predict_proba(features_scaled)[0]\n",
    "    class_idx = np.argmax(probabilities)\n",
    "    confidence = probabilities[class_idx]\n",
    "    \n",
    "    return class_names[class_idx], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18fcd260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始从 ../Data 加载数据...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   0%|          | 0/9719 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理类别 '数字' (539个文件)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   0%|          | 1/9719 [00:00<52:41,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: ../Data/00/21307130052_00_19.dat 语音段太短(128采样点)，填充至512采样点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   0%|          | 3/9719 [00:06<6:35:48,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: ../Data/00/22307130038_00_18.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/21307130052_00_11.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/21307130052_00_10.dat 语音段太短(128采样点)，填充至512采样点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   0%|          | 44/9719 [00:11<36:22,  4.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: ../Data/00/22307130038_00_07.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/21307130052_00_12.dat 语音段太短(128采样点)，填充至512采样点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   1%|          | 88/9719 [00:16<23:34,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: ../Data/00/22307130038_00_16.dat 语音段太短(128采样点)，填充至512采样点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   1%|▏         | 128/9719 [00:21<20:40,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: ../Data/00/22307130013_00_17.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/21307130052_00_07.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/21307130052_00_16.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/21307130052_00_18.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/22307130038_00_12.dat 语音段太短(128采样点)，填充至512采样点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   2%|▏         | 172/9719 [00:26<19:37,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: ../Data/00/21307130052_00_13.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/22307130013_00_01.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/21307130052_00_20.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/22307130038_00_06.dat 语音段太短(384采样点)，填充至512采样点\n",
      "警告: ../Data/00/21307130052_00_09.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/22307130038_00_11.dat 语音段太短(128采样点)，填充至512采样点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   2%|▏         | 241/9719 [00:28<11:17, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: ../Data/00/21307130150-00-20.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/22307130013_00_20.dat 语音段太短(128采样点)，填充至512采样点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   3%|▎         | 250/9719 [00:29<11:48, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: ../Data/00/21307130150-00-18.dat 语音段太短(128采样点)，填充至512采样点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   3%|▎         | 262/9719 [00:36<1:17:13,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: ../Data/00/21307130052_00_03.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/21307130052_00_02.dat 语音段太短(128采样点)，填充至512采样点\n",
      "警告: ../Data/00/22307130013_00_06.dat 语音段太短(128采样点)，填充至512采样点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度:   3%|▎         | 291/9719 [00:34<18:23,  8.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: ../Data/00/21307130150-00-16.dat 语音段太短(128采样点)，填充至512采样点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m classes = [\u001b[33m\"\u001b[39m\u001b[33m数字\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m语音\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m语言\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m处理\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m中国\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m忠告\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m北京\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m背景\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m上海\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      2\u001b[39m               \u001b[33m\"\u001b[39m\u001b[33mSpeech\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSpeaker\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSignal\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSequence\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mProcessing\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPrint\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mProject\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mFile\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mOpen\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m features, labels = \u001b[43mprepareData\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../Data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mprepareData\u001b[39m\u001b[34m(base_dir, classes)\u001b[39m\n\u001b[32m     75\u001b[39m filepath = os.path.join(class_dir, filename)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     feature = \u001b[43mextractFeature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     79\u001b[39m         features.append(feature)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mextractFeature\u001b[39m\u001b[34m(audio_file, sr, win)\u001b[39m\n\u001b[32m     20\u001b[39m     y_speech = np.pad(y_speech, (\u001b[32m0\u001b[39m, min_length - \u001b[38;5;28mlen\u001b[39m(y_speech)), \u001b[33m'\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# print(\"Start time:\", start)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# print(\"End time:\", end)\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# print(\"Segment Num:\", len(segments))\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# print(\"-\" * 20)\u001b[39;00m\n\u001b[32m     26\u001b[39m \n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 提取MFCC特征\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m mfcc_feature = \u001b[43mcomputeMFCC\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_speech\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m26\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m mfcc_mean = np.mean(mfcc_feature, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     31\u001b[39m mfcc_std = np.std(mfcc_feature, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSP/PJ/dsp.py:119\u001b[39m, in \u001b[36mcomputeMFCC\u001b[39m\u001b[34m(y, sr, N, D, M)\u001b[39m\n\u001b[32m    116\u001b[39m y_ = preEmphasis(y)\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# 分帧 + STFT\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m spec = \u001b[43mSTFT\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m                \u001b[38;5;66;03m# (频率, 窗口)\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# 转换为功率谱\u001b[39;00m\n\u001b[32m    122\u001b[39m power_spec = np.square(spec) / N            \u001b[38;5;66;03m# (频率, 窗口)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSP/PJ/dsp.py:62\u001b[39m, in \u001b[36mSTFT\u001b[39m\u001b[34m(y, sr, win, step)\u001b[39m\n\u001b[32m     59\u001b[39m stft = []\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m frames:\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# 计算 FFT\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     fft = \u001b[43mFFT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     stft.append(np.abs(fft[:win // \u001b[32m2\u001b[39m + \u001b[32m1\u001b[39m])) \u001b[38;5;66;03m# 幅值取绝对值，只关心正频率\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# 转置为 (频率, 时间) 形式\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSP/PJ/dsp.py:31\u001b[39m, in \u001b[36mFFT\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# X(k) = G(k) + e^(-2πk/N) H(k)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m G = \u001b[43mFFT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m# g(r) = x(2r)\u001b[39;00m\n\u001b[32m     32\u001b[39m H = FFT(x[\u001b[32m1\u001b[39m::\u001b[32m2\u001b[39m])      \u001b[38;5;66;03m# h(r) = x(2r+1)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 旋转因子列表\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# W1, W2, ..., W(N/2-1)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSP/PJ/dsp.py:32\u001b[39m, in \u001b[36mFFT\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# X(k) = G(k) + e^(-2πk/N) H(k)\u001b[39;00m\n\u001b[32m     31\u001b[39m G = FFT(x[\u001b[32m0\u001b[39m::\u001b[32m2\u001b[39m])     \u001b[38;5;66;03m# g(r) = x(2r)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m H = \u001b[43mFFT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# h(r) = x(2r+1)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 旋转因子列表\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# W1, W2, ..., W(N/2-1)\u001b[39;00m\n\u001b[32m     36\u001b[39m W = np.exp(-\u001b[32m2\u001b[39mj * np.pi * np.arange(N // \u001b[32m2\u001b[39m) / N)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSP/PJ/dsp.py:32\u001b[39m, in \u001b[36mFFT\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# X(k) = G(k) + e^(-2πk/N) H(k)\u001b[39;00m\n\u001b[32m     31\u001b[39m G = FFT(x[\u001b[32m0\u001b[39m::\u001b[32m2\u001b[39m])     \u001b[38;5;66;03m# g(r) = x(2r)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m H = \u001b[43mFFT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# h(r) = x(2r+1)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 旋转因子列表\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# W1, W2, ..., W(N/2-1)\u001b[39;00m\n\u001b[32m     36\u001b[39m W = np.exp(-\u001b[32m2\u001b[39mj * np.pi * np.arange(N // \u001b[32m2\u001b[39m) / N)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSP/PJ/dsp.py:31\u001b[39m, in \u001b[36mFFT\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# X(k) = G(k) + e^(-2πk/N) H(k)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m G = \u001b[43mFFT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m# g(r) = x(2r)\u001b[39;00m\n\u001b[32m     32\u001b[39m H = FFT(x[\u001b[32m1\u001b[39m::\u001b[32m2\u001b[39m])      \u001b[38;5;66;03m# h(r) = x(2r+1)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 旋转因子列表\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# W1, W2, ..., W(N/2-1)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSP/PJ/dsp.py:32\u001b[39m, in \u001b[36mFFT\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# X(k) = G(k) + e^(-2πk/N) H(k)\u001b[39;00m\n\u001b[32m     31\u001b[39m G = FFT(x[\u001b[32m0\u001b[39m::\u001b[32m2\u001b[39m])     \u001b[38;5;66;03m# g(r) = x(2r)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m H = \u001b[43mFFT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# h(r) = x(2r+1)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 旋转因子列表\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# W1, W2, ..., W(N/2-1)\u001b[39;00m\n\u001b[32m     36\u001b[39m W = np.exp(-\u001b[32m2\u001b[39mj * np.pi * np.arange(N // \u001b[32m2\u001b[39m) / N)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSP/PJ/dsp.py:32\u001b[39m, in \u001b[36mFFT\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# X(k) = G(k) + e^(-2πk/N) H(k)\u001b[39;00m\n\u001b[32m     31\u001b[39m G = FFT(x[\u001b[32m0\u001b[39m::\u001b[32m2\u001b[39m])     \u001b[38;5;66;03m# g(r) = x(2r)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m H = \u001b[43mFFT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# h(r) = x(2r+1)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 旋转因子列表\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# W1, W2, ..., W(N/2-1)\u001b[39;00m\n\u001b[32m     36\u001b[39m W = np.exp(-\u001b[32m2\u001b[39mj * np.pi * np.arange(N // \u001b[32m2\u001b[39m) / N)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSP/PJ/dsp.py:36\u001b[39m, in \u001b[36mFFT\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     32\u001b[39m H = FFT(x[\u001b[32m1\u001b[39m::\u001b[32m2\u001b[39m])      \u001b[38;5;66;03m# h(r) = x(2r+1)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 旋转因子列表\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# W1, W2, ..., W(N/2-1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m W = np.exp(-\u001b[32m2\u001b[39mj * np.pi * \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m / N)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[32m     39\u001b[39m X = np.zeros(N, dtype=\u001b[38;5;28mcomplex\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "classes = [\"数字\", \"语音\", \"语言\", \"处理\", \"中国\", \"忠告\", \"北京\", \"背景\", \"上海\", \n",
    "              \"Speech\", \"Speaker\", \"Signal\", \"Sequence\", \"Processing\", \"Print\", \"Project\", \"File\", \"Open\"]\n",
    "\n",
    "features, labels = prepareData('../Data', classes)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
